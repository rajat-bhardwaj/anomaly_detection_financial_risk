import os
import json
import pandas as pd
import numpy as np
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold


class ModelTrainingData():

    def __init__(self):

        self.path = os.path.dirname(os.path.realpath('__file__'))
        self.model_parameters = json.loads(
            open(os.path.join(self.path, 'training_config.json')).read())

        self.rng = np.random.RandomState(42)
        self.n_val_samples = self.model_parameters.get('training').get(
            'n_val_samples')
        self.fraction = self.model_parameters.get('training').get(
            'train_frac_hp_tuning')
        self.n_processes = self.model_parameters.get('training').get(
            'n_processes')
        self.contamination = self.model_parameters.get('training').get(
            'contamination')
        self.label = -1

    def get_dataset(self):
        """
        Read the data from the csv files
        """

        train = pd.read_csv(os.path.join(self.path, 'data/sample_train.csv'),
                            header=None)
        dev = pd.read_csv(os.path.join(self.path, 'data/sample_dev.csv'),
                          header=None)
        dev.rename(columns={264: 'label'}, inplace=True)

        return train, dev

    def val_contamination_sample(self, validation_data):
        """
        This function generates the stratified samples from the given dataset.
        It ensures the contamination values remains the same for each sample.

        Args:
        validation_data: Pandas DF
        label: label specifying the positively labelled data

        Return:

        List of pandas df
        """
        # 1. generate n samples based on fraction
        unlabelled = validation_data[validation_data.label != self.label]
        labelled = validation_data[validation_data.label == self.label]

        # 2. add labelled data samples to ensure the contamination
        # generate samples of labelled/positive
        sample_labels = labelled.sample(frac=1,
                                        replace=True,
                                        random_state=self.rng)

        # contamination = labelled/unlabelled
        n_label_datapoints = int(labelled.shape[0] / self.contamination) if int(
            labelled.shape[0] / self.contamination) > 0 else 1

        # generate samples of unlabelled/negative validation data
        sample_unlabelled = unlabelled.sample(n=n_label_datapoints,
                                              replace=True,
                                              random_state=self.rng)

        val_samples = pd.concat([sample_unlabelled, sample_labels])

        return val_samples

    def stratified_val_samples(self, validation_data):
        """
        This funciton generates stratified samples from the given dataset
        by approx. maintaining the contamination value.
        Currently supports number of samples in the order of 4.

        Args:
        validation_data: Pandas DF
        """

        output = []
        n_rep = int(self.n_val_samples /
                    4) if int(self.n_val_samples / 4) > 0 else 1

        rkf = RepeatedStratifiedKFold(n_splits=2,
                                      n_repeats=n_rep,
                                      random_state=self.rng)

        n_samples = validation_data.shape[0]
        for train_index, test_index in rkf.split(np.zeros(n_samples),
                                                 validation_data.label):
            X_train, X_test = validation_data.iloc[
                train_index], validation_data.iloc[test_index]
            output.extend([X_train, X_test])

        return output

    def compute_pr_auc(self, y_true, pred_score):
        """
        Computes the Precision, Recall AUC value for the given input

        ARGS:
        y_true: np array of true labels from the validation dataset
        pred_score: np array of prediciton scores generated by the model

        Returns:
        np array of AUC values for each validation sample
        """

        precision_recall_curve_list = [
            metrics.precision_recall_curve(y_true=y_true[i],
                                           probas_pred=pred_score[i],
                                           pos_label=self.label)
            for i in range(0, self.n_val_samples)
        ]
        auc_value = [
            metrics.auc(recall, precision)
            for precision, recall, _ in precision_recall_curve_list
        ]

        # average AUC over all samples
        average_auc = np.mean(auc_value)
        sd_auc = np.std(auc_value)

        return average_auc, sd_auc
